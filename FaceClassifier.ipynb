{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"FaceClassifier.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"XtrMKCTCFJyv"},"source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from keras.preprocessing import image\n","from sklearn.model_selection import train_test_split\n","import time\n","import matplotlib.pyplot as plt\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywUWMSk_NO7N"},"source":[""]},{"cell_type":"code","metadata":{"id":"y10HRHlLFJzA"},"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzncendBFJzC","outputId":"7c87cd15-9d0f-419e-bd4f-6b154a5e7189"},"source":["tqdm.pandas()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n","  from pandas import Panel\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BisSZbz2FJzE"},"source":["train_df = pd.read_csv(r\"C:\\Users\\admin\\fairface_label_train.csv\")\n","test_df = pd.read_csv(r\"C:\\Users\\admin\\fairface_label_val.csv\")\n","\n","for x in range(1000, 86744):\n","    train_df.drop(index=[x], inplace=True)\n","for x in range(1000, 10954):\n","    test_df.drop(index=[x], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmm0hR74FJzG","outputId":"7249ab45-13a0-4de2-b6f8-ea83a62fdcd6"},"source":["print(\"trainset consists of \",train_df.shape)\n","print(\"test set consist of \",test_df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["trainset consists of  (1000, 5)\n","test set consist of  (1000, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VYUbn2jtFJzH"},"source":["train_df['file'] = 'FairFace/'+train_df['file']\n","test_df['file'] = 'FairFace/'+test_df['file']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbYFLPUBFJzH","outputId":"323e0551-a5b0-45be-be82-4ae9dbf9c101"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>race</th>\n","      <th>service_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FairFace/train/1.jpg</td>\n","      <td>50-59</td>\n","      <td>Male</td>\n","      <td>East Asian</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FairFace/train/2.jpg</td>\n","      <td>30-39</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FairFace/train/3.jpg</td>\n","      <td>3-9</td>\n","      <td>Female</td>\n","      <td>Black</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FairFace/train/4.jpg</td>\n","      <td>20-29</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FairFace/train/5.jpg</td>\n","      <td>20-29</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   file    age  gender        race  service_test\n","0  FairFace/train/1.jpg  50-59    Male  East Asian          True\n","1  FairFace/train/2.jpg  30-39  Female      Indian         False\n","2  FairFace/train/3.jpg    3-9  Female       Black         False\n","3  FairFace/train/4.jpg  20-29  Female      Indian          True\n","4  FairFace/train/5.jpg  20-29  Female      Indian          True"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"x7RkHwC1FJzI","outputId":"4ae706be-3d54-4ed4-e224-ed52dba665e8"},"source":["100*train_df.groupby(['race']).count()[['file']]/train_df.groupby(['race']).count()[['file']].sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","    </tr>\n","    <tr>\n","      <th>race</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Black</th>\n","      <td>14.7</td>\n","    </tr>\n","    <tr>\n","      <th>East Asian</th>\n","      <td>12.8</td>\n","    </tr>\n","    <tr>\n","      <th>Indian</th>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>Latino_Hispanic</th>\n","      <td>17.2</td>\n","    </tr>\n","    <tr>\n","      <th>Middle Eastern</th>\n","      <td>9.6</td>\n","    </tr>\n","    <tr>\n","      <th>Southeast Asian</th>\n","      <td>11.9</td>\n","    </tr>\n","    <tr>\n","      <th>White</th>\n","      <td>19.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 file\n","race                 \n","Black            14.7\n","East Asian       12.8\n","Indian           14.0\n","Latino_Hispanic  17.2\n","Middle Eastern    9.6\n","Southeast Asian  11.9\n","White            19.8"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"rHzY7d3jFJzJ"},"source":["idx = train_df[(train_df['race'] == 'East Asian') | (train_df['race'] == 'Southeast Asian')].index\n","train_df.loc[idx, 'race'] = 'Asian'\n","\n","idx = test_df[(test_df['race'] == 'East Asian') | (test_df['race'] == 'Southeast Asian')].index\n","test_df.loc[idx, 'race'] = 'Asian'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4plJ5mXFJzK","outputId":"9f6e8a06-6541-4548-bccd-52167d4b1e09"},"source":["100*train_df.groupby(['race']).count()[['file']]/train_df.groupby(['race']).count()[['file']].sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","    </tr>\n","    <tr>\n","      <th>race</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Asian</th>\n","      <td>24.7</td>\n","    </tr>\n","    <tr>\n","      <th>Black</th>\n","      <td>14.7</td>\n","    </tr>\n","    <tr>\n","      <th>Indian</th>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>Latino_Hispanic</th>\n","      <td>17.2</td>\n","    </tr>\n","    <tr>\n","      <th>Middle Eastern</th>\n","      <td>9.6</td>\n","    </tr>\n","    <tr>\n","      <th>White</th>\n","      <td>19.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 file\n","race                 \n","Asian            24.7\n","Black            14.7\n","Indian           14.0\n","Latino_Hispanic  17.2\n","Middle Eastern    9.6\n","White            19.8"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"iCFtsVAkFJzL"},"source":["target_size = (224, 224)\n","\n","def getImagePixels(file):\n","    #print(file)\n","    img = image.load_img(file, grayscale=False, target_size=target_size)\n","    x = image.img_to_array(img).reshape(1, -1)[0]\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOQSwmpuFJzM","outputId":"0a78969a-70b7-4098-e7ba-579ffafef0b1"},"source":["train_df['pixels'] = train_df['file'].progress_apply(getImagePixels)\n","test_df['pixels'] = test_df['file'].progress_apply(getImagePixels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 232.92it/s]\n","100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 317.41it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ee0WbuTqFJzN","outputId":"34b5152d-0f17-49d8-d1a6-ae5dec865a51"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>race</th>\n","      <th>service_test</th>\n","      <th>pixels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FairFace/train/1.jpg</td>\n","      <td>50-59</td>\n","      <td>Male</td>\n","      <td>Asian</td>\n","      <td>True</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FairFace/train/2.jpg</td>\n","      <td>30-39</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>False</td>\n","      <td>[137.0, 128.0, 71.0, 133.0, 124.0, 67.0, 128.0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FairFace/train/3.jpg</td>\n","      <td>3-9</td>\n","      <td>Female</td>\n","      <td>Black</td>\n","      <td>False</td>\n","      <td>[172.0, 106.0, 82.0, 159.0, 95.0, 70.0, 152.0,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FairFace/train/4.jpg</td>\n","      <td>20-29</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>True</td>\n","      <td>[37.0, 48.0, 44.0, 39.0, 50.0, 46.0, 37.0, 48....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FairFace/train/5.jpg</td>\n","      <td>20-29</td>\n","      <td>Female</td>\n","      <td>Indian</td>\n","      <td>True</td>\n","      <td>[171.0, 123.0, 59.0, 177.0, 116.0, 51.0, 195.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   file    age  gender    race  service_test  \\\n","0  FairFace/train/1.jpg  50-59    Male   Asian          True   \n","1  FairFace/train/2.jpg  30-39  Female  Indian         False   \n","2  FairFace/train/3.jpg    3-9  Female   Black         False   \n","3  FairFace/train/4.jpg  20-29  Female  Indian          True   \n","4  FairFace/train/5.jpg  20-29  Female  Indian          True   \n","\n","                                              pixels  \n","0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","1  [137.0, 128.0, 71.0, 133.0, 124.0, 67.0, 128.0...  \n","2  [172.0, 106.0, 82.0, 159.0, 95.0, 70.0, 152.0,...  \n","3  [37.0, 48.0, 44.0, 39.0, 50.0, 46.0, 37.0, 48....  \n","4  [171.0, 123.0, 59.0, 177.0, 116.0, 51.0, 195.0...  "]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"J0uvz6uQFJzO"},"source":["train_features = []; test_features = []\n","\n","for i in range(0, train_df.shape[0]):\n","    train_features.append(train_df['pixels'].values[i])\n","\n","for i in range(0, test_df.shape[0]):\n","    test_features.append(test_df['pixels'].values[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPepfbY9FJzO","outputId":"24ed351a-1fd8-4be6-ebf6-ebefe0fed359"},"source":["tic = time.time()\n","\n","train_features = np.array(train_features)\n","train_features = train_features.reshape(train_features.shape[0], 224, 224, 3)\n","\n","test_features = np.array(test_features)\n","test_features = test_features.reshape(test_features.shape[0], 224, 224, 3)\n","\n","toc = time.time()\n","\n","print(\"converted to numpy in \",toc-tic,\"seconds\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["converted to numpy in  0.5924167633056641 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QOFEreCeFJzP","outputId":"155d7742-509e-45fa-8029-e56c7375d84b"},"source":["tic = time.time()\n","\n","train_features = train_features / 255\n","test_features = test_features / 255\n","\n","toc = time.time()\n","\n","print(\"converted to numpy in \",toc-tic,\"seconds\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["converted to numpy in  0.5056507587432861 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lmN6BF9YFJzQ"},"source":["train_label = train_df[['race']]\n","test_label = test_df[['race']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHIrrlRdFJzR"},"source":["races = train_df['race'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xs3fKogZFJzR","outputId":"c83978c5-ed54-42f5-e1f4-57da626295f8"},"source":["for j in range(len(races)): #label encoding\n","    current_race = races[j]\n","    print(\"replacing \",current_race,\" to \", j+1)\n","    train_label['race'] = train_label['race'].replace(current_race, str(j+1))\n","    test_label['race'] = test_label['race'].replace(current_race, str(j+1))\n","\n","train_label = train_label.astype({'race': 'int32'})\n","test_label = test_label.astype({'race': 'int32'})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["replacing  Asian  to  1\n","replacing  Indian  to  2\n","replacing  Black  to  3\n","replacing  White  to  4\n","replacing  Middle Eastern  to  5\n","replacing  Latino_Hispanic  to  6\n"],"name":"stdout"},{"output_type":"stream","text":["<ipython-input-68-8c1856772b82>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_label['race'] = train_label['race'].replace(current_race, str(j+1))\n","<ipython-input-68-8c1856772b82>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_label['race'] = test_label['race'].replace(current_race, str(j+1))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cJxvWXejFJzS","outputId":"afd96f21-3b41-4c87-845e-3692df6c8052"},"source":["train_label.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>race</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   race\n","0     1\n","1     2\n","2     3\n","3     2\n","4     2"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"9lTM0hEoFJzT"},"source":["train_target = pd.get_dummies(train_label['race'], prefix='race')\n","test_target = pd.get_dummies(test_label['race'], prefix='race')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dkAc5RKFJzU","outputId":"1f128e36-38dc-4332-f274-f44d97e1e81a"},"source":["train_target.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>race_1</th>\n","      <th>race_2</th>\n","      <th>race_3</th>\n","      <th>race_4</th>\n","      <th>race_5</th>\n","      <th>race_6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   race_1  race_2  race_3  race_4  race_5  race_6\n","0       1       0       0       0       0       0\n","1       0       1       0       0       0       0\n","2       0       0       1       0       0       0\n","3       0       1       0       0       0       0\n","4       0       1       0       0       0       0"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"nm5ESDMJFJzU"},"source":["train_x, val_x, train_y, val_y = train_test_split(train_features, train_target.values\n","                                        , test_size=0.12, random_state=17)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kD3gb77DFJzV"},"source":["import keras\n","from keras.preprocessing import image\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n","from keras.layers import Conv2D, AveragePooling2D\n","from keras.models import Model, Sequential"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HzYnxszFJzW"},"source":["#VGG-Face model\n","model = Sequential()\n","model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n","model.add(Convolution2D(64, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(128, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(256, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(ZeroPadding2D((1,1)))\n","model.add(Convolution2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2,2), strides=(2,2)))\n"," \n","model.add(Convolution2D(4096, (7, 7), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(4096, (1, 1), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(2622, (1, 1)))\n","model.add(Flatten())\n","model.add(Activation('softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcMU24hoFJzY"},"source":["model.load_weights('vgg_face_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gMsHoT68FJzZ"},"source":["num_of_classes = 6#len(races)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jV6Jmn2yFJzZ"},"source":["#freeze all layers of VGG-Face except last 7 one\n","for layer in model.layers[:-7]:\n","    layer.trainable = False\n","\n","base_model_output = Sequential()\n","base_model_output = Convolution2D(num_of_classes, (1, 1), name='predictions')(model.layers[-4].output)\n","base_model_output = Flatten()(base_model_output)\n","base_model_output = Activation('softmax')(base_model_output)\n","\n","race_model = Model(inputs=model.input, outputs=base_model_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Nqyhy7rFJza"},"source":["race_model.compile(loss='categorical_crossentropy'\n","                  , optimizer=keras.optimizers.Adam()\n","                  , metrics=['accuracy']\n","                 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Mc5UZEsFJza"},"source":["race_model.load_weights('race_model_single_batch.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rh-bwEEcFJzb"},"source":["checkpointer = ModelCheckpoint(\n","    filepath='race_model_single_batch.hdf5'\n","    , monitor = \"val_loss\"\n","    , verbose=1\n","    , save_best_only=True\n","    , mode = 'auto'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EAEj8M2PFJzc"},"source":["patience = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LMW2sA1FJzc"},"source":["val_scores = []; train_scores = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"syDEzhhoFJzc","outputId":"e6c34156-28f6-49ac-9670-055b77ac2b4e"},"source":["enableBatch = True\n","\n","epochs = 1000\n","\n","if enableBatch != True:\n","    early_stop = EarlyStopping(monitor='val_loss', patience=patience) \n","    \n","    score = race_model.fit(\n","        train_x, train_y\n","        , epochs=epochs\n","        , validation_data=(val_x, val_y)\n","        , callbacks=[checkpointer, early_stop]\n","    )\n","else:\n","    batch_size = pow(2, 14)\n","    last_improvement = 0\n","    best_iteration = 0\n","    \n","    loss = 1000000 #initialize as a large value\n","    \n","    for i in range(0, epochs):\n","        \n","        print(\"Epoch \", i, \". \", end='')\n","        \n","        ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n","        \n","        score = race_model.fit(\n","            train_x[ix_train], train_y[ix_train]\n","            , epochs=1\n","            , validation_data=(val_x, val_y)\n","            , callbacks=[checkpointer]\n","        )\n","        \n","        val_loss = score.history['val_loss'][0]\n","        train_loss = score.history['loss'][0]\n","        \n","        val_scores.append(val_loss)\n","        train_scores.append(train_loss)\n","        \n","        #--------------------------------\n","        \n","        if val_loss < loss:\n","            loss = val_loss * 1\n","            last_improvement = 0\n","            best_iteration = i * 1\n","        else:\n","            last_improvement = last_improvement + 1\n","            print(\"try to decrease val loss for \",patience - last_improvement,\" epochs more\")\n","        \n","        #--------------------------------\n","        \n","        if last_improvement == patience:\n","            print(\"there is no loss decrease in validation for \",patience,\" epochs. early stopped\")\n","            break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch  0 . "],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":" OOM when allocating tensor with shape[32,224,224,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node model_1/conv2d_16/Relu (defined at <ipython-input-83-27e9307be4f9>:27) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_3673]\n\nFunction call stack:\ntrain_function\n","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[1;32m<ipython-input-83-27e9307be4f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mix_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         score = race_model.fit(\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,224,224,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node model_1/conv2d_16/Relu (defined at <ipython-input-83-27e9307be4f9>:27) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_3673]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"id":"KvSsRVjJFJzd"},"source":["if enableBatch != True:\n","    plt.plot(score.history['val_loss'], label='val_loss')\n","    plt.plot(score.history['loss'], label='train_loss')\n","    plt.legend(loc='upper right')\n","    plt.show()\n","else:\n","    plt.plot(val_scores[0:best_iteration], label='val_loss')\n","    plt.plot(train_scores[0:best_iteration], label='train_loss')\n","    plt.legend(loc='upper right')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cm-5w3k2FJzd"},"source":["if enableBatch != True:\n","    plt.plot(score.history['val_loss'][0:best_iteration], label='val_loss')\n","    plt.plot(score.history['loss'][0:best_iteration], label='train_loss')\n","    plt.legend(loc='upper right')\n","    plt.show()\n","else:\n","    plt.plot(val_scores[0:best_iteration+1], label='val_loss')\n","    plt.plot(train_scores[0:best_iteration+1], label='train_loss')\n","    plt.legend(loc='upper right')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Bn54cPsFJzd"},"source":["#restore the best weights\n","from keras.models import load_model\n","race_model = load_model(\"race_model_single_batch.hdf5\")\n","\n","race_model.save_weights('race_model_single_batch.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iUZLBSJFJze"},"source":["test_perf = race_model.evaluate(test_features, test_target.values, verbose=1)\n","print(test_perf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rKMAbk7FJze"},"source":["validation_perf = race_model.evaluate(val_x, val_y, verbose=1)\n","print(validation_perf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTVVsUZgFJze"},"source":["#Check model is robust\n","abs(validation_perf[0] - test_perf[0]) < 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDov5CdoFJze"},"source":["predictions = race_model.predict(test_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"poT9lQo4FJzf"},"source":["prediction_classes = []; actual_classes = []\n","\n","for i in range(0, predictions.shape[0]):\n","    prediction = np.argmax(predictions[i])\n","    prediction_classes.append(races[prediction])\n","    actual = np.argmax(test_target.values[i])\n","    actual_classes.append(races[actual])\n","    \n","    if i in [\n","        375, 470, 750, 758, 875, 992, 1061, 2181, 2255, 4725, 4944 #latino\n","        , 124, 339, 762, 913, 1340, 1363, 2205 #black\n","        , 33, 83, 237, 609, 817, 1223, 1377 #asian\n","        , 109, 203, 899, 1094, 1180, 1250, 1395, 1556 #indian\n","        , 638, 718, 1088, 1460, 4396, 4477 #middle eastern\n","        , 413, 447, 573, 649, 723, 1258, 1274, 1430, 1485 #white\n","        , 17, 235, #misclassified\n","    ]:\n","        print(i)\n","        print(\"Actual: \",races[actual])\n","        print(\"Predicted: \",races[prediction])\n","        \n","        img = (test_df.iloc[i]['pixels'].reshape([224, 224, 3])) / 255\n","        plt.imshow(img)\n","        plt.show()\n","        print(\"----------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7r9iNT8FJzf"},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IetYIEnFJzf"},"source":["cm = confusion_matrix(actual_classes, prediction_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QzvOusCzFJzf"},"source":["cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JRF3K62FJzf"},"source":["df_cm = pd.DataFrame(cm, index=races, columns=races)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxTEeVUZFJzf"},"source":["sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 10})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xyl3KzXRFJzg"},"source":["races = ['Asian', 'Indian', 'Black', 'White', 'Middle Eastern', 'Latino_Hispanic']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l9nCYjSSFJzg"},"source":["demo_set = ['richard.jpg', 'erlich.jpg', 'dinesh.jpg', 'jian-yang.jpg', 'russ.jpg', 'gilfoyle.jpg', 'jared.jpg']\n","\n","for file in demo_set:\n","    path = 'demo/%s' % (file) \n","    img = image.load_img(path, grayscale=False, target_size=(224, 224, 3))\n","    img = image.img_to_array(img).reshape(1, -1)[0]\n","    img = img.reshape(224, 224, 3)\n","    img = img / 255\n","    \n","    plt.imshow(img)\n","    plt.show()\n","    \n","    img = np.expand_dims(img, axis=0) \n","\n","    prediction_proba = race_model.predict(img)\n","\n","    print(\"Prediction: \",races[np.argmax(prediction_proba)])\n","    print(\"---------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kd2yFYQXFJzg"},"source":[""],"execution_count":null,"outputs":[]}]}